{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x = th.randn(10, 128)\n",
    "y = th.randint(0, 4, (10,))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dab1f3b9a4b2f78a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DataAndLabelEncoder(nn.Module):\n",
    "    def __init__(self, x_max_dim: int, nb_class_max: int, y_emb_dim :int, hidden_dim: int, output_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.__y_emb = nn.Embedding(nb_class_max, y_emb_dim)\n",
    "        \n",
    "        self.__encoder = nn.Sequential(\n",
    "            nn.Linear(x_max_dim + y_emb_dim, hidden_dim),\n",
    "            nn.Mish(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Mish(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Mish(),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: th.Tensor, y: th.Tensor) -> th.Tensor:\n",
    "        y_emb = self.__y_emb(y)\n",
    "        \n",
    "        out = th.cat([x, y_emb], dim=1)\n",
    "        out = self.__encoder(out)\n",
    "        \n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad40edcd5ae1fe90",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DataEncoder(nn.Sequential):\n",
    "    def __init__(self, x_max_dim: int, hidden_dim: int, output_dim: int) -> None:\n",
    "        super().__init__(\n",
    "            nn.Linear(x_max_dim, hidden_dim),\n",
    "            nn.Mish(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Mish(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Mish(),\n",
    "            nn.BatchNorm1d(output_dim)\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51068960163bc7a5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "enc= DataAndLabelEncoder(128, 5, 128, 128, 128)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e5d7f278b33f978",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_enc = enc(x, y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ea6ed360e958b52",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_enc.size()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9266a8f68f5530e7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "enc2 = DataEncoder(128, 128, 128)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92f77f7b53a6d83c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_enc_2 = enc2(x)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "791cba87fed271ef",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_enc_2.size()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a24b3c3fa8e1491",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trf_enc = "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10b97392120f1f94",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_mask(x_train: th.Tensor, x_test: th.Tensor) -> th.Tensor:\n",
    "    mask = th.eye(x_train.size(0) + x_test.size(0))\n",
    "    \n",
    "    mask[:, :x_train.size(0)] = 1\n",
    "    \n",
    "    return mask"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "671e670e353e6c47",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "src_mask = get_mask(x_enc, x_enc_2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f0e24002c1863ff",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "enc_input = th.cat([x_enc, x_enc_2], dim=0)\n",
    "out = trf_enc(enc_input, mask=src_mask)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5a3fb399f2ab77f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "out.size()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dd702f03ad07d06",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class PFN(nn.Module):\n",
    "    def __init__(self, model_dim: int, hidden_dim: int, nb_class: int) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.__trf = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(model_dim, 4, hidden_dim, activation=F.gelu, batch_first=True),\n",
    "            6\n",
    "        )\n",
    "        \n",
    "        self.__to_class = nn.Linear(model_dim, nb_class)\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_mask(x_train: th.Tensor, x_test: th.Tensor) -> th.Tensor:\n",
    "        mask = th.eye(x_train.size(0) + x_test.size(0))\n",
    "        \n",
    "        mask[:, :x_train.size(0)] = 1\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def forward(self, x_train: th.Tensor, x_test: th.Tensor) -> th.Tensor:\n",
    "        src_mask = self.get_mask(x_train, x_test)\n",
    "        \n",
    "        enc_input = th.cat([x_train, x_test], dim=0)\n",
    "        \n",
    "        out = self.__trf(enc_input, mask=src_mask)[x_train.size(0):, :]\n",
    "        out = self.__to_class(out)\n",
    "        \n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcbcae8055539296",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pfn = PFN(128, 256, 10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad9d2a7f215e1f2f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "out = pfn(x_enc, x_enc_2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c56f331eeb18046",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "out.size()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "950a00d2f66dc36a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "195b63a7918d1df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
